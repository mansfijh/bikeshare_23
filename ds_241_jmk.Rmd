---
title: "Final Project"
output: html_notebook
authors: "Joshua Allessio, Kashyap Vallur and Marco Camalich"
---

## Problem Statement
Washington DC's public bikeshare dataset is a classic data science project. Much can be gleaned from this data. In this report, we set out to discover which of the bike stations are particularly efficient or inefficient. The goal is to create a visualization of the net flow of bikes for each station over time. 

If the net flow for a bike station often stays close to 0, we may assume that that station is in an optimal position and hosts enough bicycles. Furthermore, high turnover of bikes can imply that a bike station is in an optimal position, while low turnover of bikes may imply that that bike station is not placed in an optimal location. 

Another pattern that may arise could be a bike station that has a strong negative netflow early in the day, followed by a stagnant period of netflow later in the day. This would imply that the bike station has quickly become vacant - now offering no bicycles for potential riders. Potential solution for this particular problem might be increasing the size of that station, creating a new one nearby, or making a larger change to the infrastructure of the bikeshare. 


```{r}
required_packages <- c("tidyverse", "janitor", "here", "openmeteo", "lubridate", "forcats", "dplyr")

for (packages in required_packages) {
  if (!require(packages, character.only = TRUE)) {
    install.packages(packages, dependencies = TRUE)
    library(packages, character.only = TRUE)
  }
}

if (all(sapply(required_packages, requireNamespace, quietly = TRUE))) {
  cat("All required packages are loaded.\n")
} else {
  warning("Some packages failed to load.")
}

```

## Create a function to filter useless data from the data set
This function takes the DC bikeshare data sets and removes columns with NA values, as well as rides which lasted
less than 30 seconds or more than 13 hours. 
```{r}
filter_bikeshare <- function(df) {
  df |> filter(
    !is.na(start_station_name) & !is.na(start_station_id) & start_station_name != "" & start_station_id != "" &
    !is.na(end_station_name) & !is.na(end_station_id) & end_station_name != "" & end_station_id != "" &
    !is.na(start_lat) & !is.na(start_lng) & !is.na(end_lng)    
  )
  df <- df |> 
    mutate(duration = as.numeric(difftime(ended_at, started_at))) |>  
    filter(duration > 30) |>  # Longer than 30 seconds
    filter (duration < 46800) # Less than 13 hours
return(df)
}
```


## Import the data
```{r}
df_01=read_csv(here("data_raw", "202301-capitalbikeshare-tripdata.csv"))
df_02=read_csv(here("data_raw", "202302-capitalbikeshare-tripdata.csv"))
df_03=read_csv(here("data_raw", "202303-capitalbikeshare-tripdata.csv"))
df_04=read_csv(here("data_raw", "202304-capitalbikeshare-tripdata.csv"))
df_05=read_csv(here("data_raw", "202305-capitalbikeshare-tripdata.csv"))
df_06=read_csv(here("data_raw", "202306-capitalbikeshare-tripdata.csv"))
df_07=read_csv(here("data_raw", "202307-capitalbikeshare-tripdata.csv"))
df_08=read_csv(here("data_raw", "202308-capitalbikeshare-tripdata.csv"))
df_09=read_csv(here("data_raw", "202309-capitalbikeshare-tripdata.csv"))
df_10=read_csv(here("data_raw", "202310-capitalbikeshare-tripdata.csv"))
```

## Tidy the Data
```{r}
df_01 <- filter_bikeshare(df_01)
df_02 <- filter_bikeshare(df_02)
df_03 <- filter_bikeshare(df_03)
df_04 <- filter_bikeshare(df_04)
df_05 <- filter_bikeshare(df_05)
df_06 <- filter_bikeshare(df_06)
df_07 <- filter_bikeshare(df_07)
df_08 <- filter_bikeshare(df_08)
df_09 <- filter_bikeshare(df_09)
df_10 <- filter_bikeshare(df_10)
```


## Aggregate the Data
Aggregate the data into one data frame and begin with a simple visualization
```{r}
all_data <- bind_rows(
  df_01, df_02, df_03, df_04, df_05, df_06, df_07, df_08, df_09, df_10,
  .id = "month"
)

all_data$started_at <- as.POSIXct(all_data$started_at, format = "%Y-%m-%d %H:%M:%S")
all_data$month <- format(all_data$started_at, "%Y-%m")

ggplot(all_data, aes(x = month)) +
  geom_bar() +
  labs(title = "Monthly Ride Counts",
       x = "Month",
       y = "Ride Counts") +
  theme_minimal()
```

```{r}
ggplot(all_data, aes(x = month, y = as.numeric(ended_at - started_at))) +
  geom_boxplot() +
  labs(title = "Average Ride Duration by Month",
       x = "Month",
       y = "Duration (minutes)") +
  theme_minimal()
```

```{r}
ggplot(all_data, aes(x = month, fill = rideable_type)) +
  geom_bar(position = "fill") +
  labs(title = "Popular Rideable Types by Month",
       x = "Month",
       y = "Proportion") +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 100))
```



## Next Steps
Tried a few things for my idea, couldn't get it to work yet. But here's my idea in non-code form. 
1. Make a new df with columns 'time', start_station, end_station, latitude, and longitude. 
2. There is a row for every unique time value in both started_at and ended_at. 
3. If that time value is when a ride started, start_station contains the station, while end_station contains nothing.          Latitude and longitude contain the start stations coordinates. 
3b. If that time value is when a ride ended, end_station contains that station, while start_station contains nothing.          Latitude and longitude contain the end stations coordinates. 
4. Make sure this df is in chronological order. 
5. Set up a categorical variable for the different stations. 
6. Make a new column or new dataframe to hold the cumulative sum of bikes at each station. 
   If started_station is populated, the categorical value it is populated with (the bike stations) gets -1
   If end_station is populated, the categorical value it is populated with (the bike stations) gets +1
7. Group these by hour or day
8. Map

## 
```{r}
# Step 1: Create a new dataframe with the desired columns
time_data <- data.frame(time = character(),
                        start_station = character(),
                        end_station = character(),
                        latitude = numeric(),
                        longitude = numeric(),
                        stringsAsFactors = FALSE)

# Step 2: Extract unique time values from started_at and ended_at in all_data
unique_times <- unique(c(all_data$started_at, all_data$ended_at))

# Step 3: Populate the new data frames based on ride start and end times
start_data <- all_data %>%
  filter(!is.na(start_station_name)) %>%
  select(started_at, start_station_name, start_lat, start_lng) %>%
  rename(time = started_at,
         station = start_station_name,
         latitude = start_lat,
         longitude = start_lng) %>%
  mutate(bikes_out = "-1")

end_data <- all_data %>%
  filter(!is.na(end_station_name)) %>%
  select(ended_at, end_station_name, end_lat, end_lng) %>%
  rename(time = ended_at,
         station = end_station_name,
         latitude = end_lat,
         longitude = end_lng) %>%
  mutate(bikes_in = "1")

# Combine start and end data frames
time_data <- bind_rows(start_data, end_data)



# Step 4: Ensure chronological order
time_data <- time_data %>%
  arrange(as.POSIXct(time))
# Print the first few rows of the time_data dataframe for inspection
print(head(time_data))

```


## Fun With Categorical Variables (Josh attempt)
I'm sure there may be a very efficient way to do this by making use of categorical variables, but I don't have enough experience for that. Anyways...
```{r}
# Arrange the data by bike station and then by time
data2 <- time_data |>
  arrange(station, time) |>
  group_by(station) |>
  mutate(delta = 
           
           
# Simply need to element-wise sum bikes_in and bikes_out, 
# Then calculate the cumulative sum
# Then group by hour
# Then plot
```


## Fun with Categorical Variables (Kashyap / Marco work)
```{r}
# Step 5: Set up a categorical variable for stations
time_data <- time_data %>%
  mutate(station = as.factor(station))  # Assuming station is a suitable variable for categorization

# Step 6: Create a new column for cumulative sum of bikes at each station
time_data <- time_data %>%
  group_by(station) %>%
  mutate(cumulative_bikes = cumsum(ifelse(start_station != "", -1, 1)))

# Step 7: Group by hour or day
# For example, grouping by hour
time_data <- time_data %>%
  group_by(station, hour = lubridate::hour(as.POSIXct(time))) %>%
  summarise(cumulative_bikes = sum(cumulative_bikes))

# Step 8: Create a line plot of cumulative bike count over time
ggplot(time_data, aes(x = hour, y = cumulative_bikes, color = station)) +
  geom_line() +
  labs(title = "Cumulative Bike Count Over Time",
       x = "Hour",
       y = "Cumulative Bikes") +
  theme_minimal()
```

